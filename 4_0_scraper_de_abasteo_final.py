# -*- coding: utf-8 -*-
"""4.0 SCRAPER DE ABASTEO FINAL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cBAuvcuPKxFuAOTueKu7XjtlGyVCFiib
"""

# ===== CELDA 1 =====
!pip -q install pandas numpy requests beautifulsoup4 lxml openpyxl

# ===== CELDA 2 =====
import re, time, random, math
import numpy as np
import pandas as pd
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus, urljoin
from datetime import datetime

from openpyxl import load_workbook
from google.colab import files

# --- Config ---
BASE = "https://www.abasteo.mx"
IVA_RATE = 0.16  # Abasteo muestra CON IVA; tu precio max viene SIN IVA

MIN_SLEEP = 1.2
MAX_SLEEP = 2.6
TIMEOUT = 30
MAX_RETRIES = 3

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
    "Accept-Language": "es-MX,es;q=0.9,en;q=0.8",
}

def human_sleep():
    time.sleep(random.uniform(MIN_SLEEP, MAX_SLEEP))

# ===== CELDA 3 =====
def fetch(url, session: requests.Session, allow_redirects=True):
    last_err = None
    for _ in range(MAX_RETRIES):
        try:
            r = session.get(url, headers=HEADERS, timeout=TIMEOUT, allow_redirects=allow_redirects)
            r.raise_for_status()
            return r
        except Exception as e:
            last_err = e
            time.sleep(random.uniform(1.0, 2.0))
    raise last_err

def extract_json_objects_from_scripts(html: str):
    """
    Abasteo mete objetos JSON grandes en <script> (no siempre con type="application/json").
    Aquí buscamos "stockVariants" y extraemos el objeto JSON más cercano (best effort).
    """
    soup = BeautifulSoup(html, "lxml")
    scripts = soup.find_all("script")
    blobs = []

    for s in scripts:
        txt = s.get_text(strip=False)
        if not txt:
            continue
        if "stockVariants" in txt and "scalePrices" in txt:
            blobs.append(txt)

    return blobs

def try_parse_json_like(text: str):
    """
    Best-effort: intenta encontrar un JSON válido dentro del texto.
    """
    # 1) buscar el primer '{' y el último '}' que parecen encerrar un objeto grande
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        return None

    candidate = text[start:end+1]

    # 2) a veces trae cosas tipo "window.__STATE__ = {...};"
    # quitar prefijos/sufijos obvios
    candidate = candidate.strip()
    candidate = re.sub(r"^[^\{]*", "", candidate)
    candidate = re.sub(r"[^\}]*$", "", candidate)

    # 3) intentar json normal
    import json
    try:
        return json.loads(candidate)
    except:
        pass

    # 4) si falla, intentar arreglar escapes raros (mínimo)
    try:
        candidate2 = candidate.replace("\\x3C", "<").replace("\\x3E", ">")
        return json.loads(candidate2)
    except:
        return None

def deep_find_stockvariants(obj):
    """
    Busca recursivamente una lista bajo la llave 'stockVariants'.
    """
    if isinstance(obj, dict):
        if "stockVariants" in obj and isinstance(obj["stockVariants"], list):
            return obj["stockVariants"], obj
        for k, v in obj.items():
            res = deep_find_stockvariants(v)
            if res:
                return res
    elif isinstance(obj, list):
        for it in obj:
            res = deep_find_stockvariants(it)
            if res:
                return res
    return None

def safe_num(x):
    try:
        return float(x)
    except:
        return None

# ===== CELDA 4 =====
def build_search_url(code: str):
    # Abasteo usa searchparam directo
    return f"{BASE}/?cl=search&searchparam={quote_plus(code)}"

def pick_first_product_url_from_search(html: str, code: str):
    soup = BeautifulSoup(html, "lxml")
    links = soup.find_all("a", href=True)
    candidates = []

    for a in links:
        href = a["href"]
        if not href:
            continue
        if ".html" not in href:
            continue
        full = urljoin(BASE, href)
        # preferencia: que contenga el código o parte del SKU
        if code.lower().replace("/", "") in full.lower().replace("%2F", "").replace("/", ""):
            candidates.append(full)
        else:
            # también aceptar cualquiera de producto (fallback)
            candidates.append(full)

    # quitar duplicados manteniendo orden
    seen = set()
    out = []
    for u in candidates:
        if u in seen:
            continue
        seen.add(u)
        out.append(u)

    return out[0] if out else None

def resolve_product_url(code: str, session: requests.Session):
    search_url = build_search_url(code)
    r = fetch(search_url, session=session, allow_redirects=True)
    final_url = r.url

    # si ya cayó en producto directo
    if final_url.startswith(BASE) and final_url.endswith(".html"):
        return search_url, final_url, "OK_DIRECT"

    # si no, parsear search results
    product_url = pick_first_product_url_from_search(r.text, code)
    if product_url:
        return search_url, product_url, "OK_FROM_SEARCH"

    return search_url, None, "NO_PRODUCT_FOUND"

# ===== CELDA 5 =====
def parse_product_page(product_url: str, session: requests.Session):
    r = fetch(product_url, session=session, allow_redirects=True)
    html = r.text
    soup = BeautifulSoup(html, "lxml")

    # Título (best effort)
    title = None
    h1 = soup.find("h1")
    if h1:
        title = h1.get_text(" ", strip=True)

    # Intentar obtener JSON con stockVariants
    blobs = extract_json_objects_from_scripts(html)
    data_obj = None
    stockVariants = None
    root_obj = None

    for b in blobs:
        obj = try_parse_json_like(b)
        if obj is None:
            continue
        found = deep_find_stockvariants(obj)
        if found:
            stockVariants, root_obj = found
            data_obj = obj
            break

    if not stockVariants:
        # no pudimos encontrar data
        return {
            "ok": False,
            "title": title,
            "sku": None,
            "total_disponibles": None,
            "rows": [],
            "debug": {
                "html_len": len(html),
                "stockVariants_found": 0
            }
        }

    # SKU: puede venir en alguna parte de root_obj (bannerContext) o inferir por tu código
    # fallback: buscar "sku" en dict
    sku = None
    def deep_find_key(obj, key):
        if isinstance(obj, dict):
            if key in obj:
                return obj[key]
            for v in obj.values():
                r = deep_find_key(v, key)
                if r is not None:
                    return r
        elif isinstance(obj, list):
            for it in obj:
                r = deep_find_key(it, key)
                if r is not None:
                    return r
        return None

    sku = deep_find_key(root_obj, "sku")
    if isinstance(sku, dict) or isinstance(sku, list):
        sku = None
    if sku:
        sku = str(sku)

    rows = []
    total_disp = 0.0

    for idx, v in enumerate(stockVariants):
        # Bodega ID/name
        bodega = None
        # Buscar posibles campos
        for key in ["warehouse", "warehouseName", "warehouseId", "bodega", "name", "label"]:
            if isinstance(v, dict) and key in v:
                bodega = v.get(key)
                break

        if not bodega:
            # usar id o índice
            bodega = v.get("id") if isinstance(v, dict) and v.get("id") else f"ALMACEN_{idx+1}"

        stock = safe_num(v.get("stock")) if isinstance(v, dict) else None
        if stock is None:
            stock = 0.0
        total_disp += stock

        # Precio +21
        precio_21 = None
        precio_21_txt = None

        scale = v.get("scalePrices") if isinstance(v, dict) else None
        if isinstance(scale, list):
            # buscar rango donde from>=21 o range[0]==21
            candidate = None
            for sp in scale:
                if not isinstance(sp, dict):
                    continue
                fr = sp.get("from")
                rng = sp.get("range")
                if fr == 21:
                    candidate = sp
                    break
                if isinstance(rng, list) and len(rng) >= 1 and rng[0] == 21:
                    candidate = sp
                    # no break por si hay otra más precisa
                    break

            if candidate:
                # Abasteo suele tener tPrice (entero) y también fbruttprice (string)
                tprice = candidate.get("tPrice") or candidate.get("tprice")
                price = candidate.get("price")
                precio_21 = safe_num(tprice) if safe_num(tprice) not in [None, 0.0] else safe_num(price)
                precio_21_txt = candidate.get("fbruttprice") or candidate.get("fbrutprice")

        rows.append({
            "BODEGA": str(bodega),
            "BODEGA_PZAS": float(stock),
            "PRECIO_21_MAS_CON_IVA": float(precio_21) if precio_21 is not None else None,
            "PRECIO_21_MAS_TEXTO": precio_21_txt
        })

    # limpiar rows: quedarse solo con las que tienen precio +21
    rows = [r for r in rows if r["PRECIO_21_MAS_CON_IVA"] is not None]

    return {
        "ok": True,
        "title": title,
        "sku": sku,
        "total_disponibles": float(total_disp),
        "rows": rows,
        "debug": {
            "html_len": len(html),
            "stockVariants_found": len(stockVariants)
        }
    }

# ===== CELDA 6 =====
# Subir Excel de entrada (tu archivo)
uploaded = files.upload()
input_path = list(uploaded.keys())[0]
print("Archivo cargado:", input_path)

# Leer primera hoja
df_in = pd.read_excel(input_path)

# Normalizar nombres
df_in.columns = [str(c).strip().upper() for c in df_in.columns]

def find_col(posibles):
    for p in posibles:
        for c in df_in.columns:
            if p in c:
                return c
    return None

col_code = find_col(["CODIGO", "CÓDIGO", "FABRICANTE", "SKU"])
col_max  = find_col(["PRECIO MAX", "PRECIO_MAX", "MAX", "TOPE"])
col_qty  = find_col(["CANTIDAD", "QTY", "PIEZAS", "PZAS"])

if col_code is None or col_max is None:
    raise ValueError("Tu Excel debe tener una columna de CODIGO/SKU y otra de PRECIO MAX (sin IVA).")

# preparar input final
df_input = df_in[[col_code, col_max] + ([col_qty] if col_qty else [])].copy()
df_input = df_input.rename(columns={
    col_code: "CODIGO_FABRICANTE",
    col_max: "PRECIO_MAX_SIN_IVA",
})
if col_qty:
    df_input = df_input.rename(columns={col_qty: "CANTIDAD_OBJETIVO"})

df_input["CODIGO_FABRICANTE"] = df_input["CODIGO_FABRICANTE"].astype(str).str.strip()
df_input["PRECIO_MAX_SIN_IVA"] = pd.to_numeric(df_input["PRECIO_MAX_SIN_IVA"], errors="coerce")
if "CANTIDAD_OBJETIVO" in df_input.columns:
    df_input["CANTIDAD_OBJETIVO"] = pd.to_numeric(df_input["CANTIDAD_OBJETIVO"], errors="coerce")

df_input = df_input.dropna(subset=["CODIGO_FABRICANTE", "PRECIO_MAX_SIN_IVA"]).reset_index(drop=True)
df_input.head()

# ===== CELDA 7 =====
def scrape_one_code(code: str, session: requests.Session):
    ts = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
    search_url, product_url, status = resolve_product_url(code, session)

    if not product_url:
        return [{
            "TIMESTAMP": ts,
            "CODIGO_FABRICANTE": code,
            "SKU": None,
            "TITULO": None,
            "TOTAL_DISPONIBLES": None,
            "BODEGA": None,
            "BODEGA_PZAS": None,
            "PRECIO_21_MAS_CON_IVA": None,
            "PRECIO_21_MAS_SIN_IVA": None,
            "URL_BUSQUEDA": search_url,
            "URL_PRODUCTO": None,
            "STATUS": status
        }]

    human_sleep()
    parsed = parse_product_page(product_url, session)

    if not parsed["ok"] or not parsed["rows"]:
        return [{
            "TIMESTAMP": ts,
            "CODIGO_FABRICANTE": code,
            "SKU": parsed.get("sku"),
            "TITULO": parsed.get("title"),
            "TOTAL_DISPONIBLES": parsed.get("total_disponibles"),
            "BODEGA": None,
            "BODEGA_PZAS": None,
            "PRECIO_21_MAS_CON_IVA": None,
            "PRECIO_21_MAS_SIN_IVA": None,
            "URL_BUSQUEDA": search_url,
            "URL_PRODUCTO": product_url,
            "STATUS": "NO_BODEGAS_OR_NO_21PLUS_FOUND"
        }]

    out = []
    for r in parsed["rows"]:
        p_iva = r["PRECIO_21_MAS_CON_IVA"]
        p_sin = (p_iva / (1.0 + IVA_RATE)) if p_iva is not None else None

        out.append({
            "TIMESTAMP": ts,
            "CODIGO_FABRICANTE": code,
            "SKU": parsed.get("sku") or code,
            "TITULO": parsed.get("title"),
            "TOTAL_DISPONIBLES": parsed.get("total_disponibles"),
            "BODEGA": r["BODEGA"],
            "BODEGA_PZAS": r["BODEGA_PZAS"],
            "PRECIO_21_MAS_CON_IVA": p_iva,
            "PRECIO_21_MAS_SIN_IVA": p_sin,
            "PRECIO_21_MAS_TEXTO": r.get("PRECIO_21_MAS_TEXTO"),
            "URL_BUSQUEDA": search_url,
            "URL_PRODUCTO": product_url,
            "STATUS": "OK"
        })
    return out

session = requests.Session()

all_rows = []
for i, row in df_input.iterrows():
    code = row["CODIGO_FABRICANTE"]
    try:
        all_rows.extend(scrape_one_code(code, session))
    except Exception as e:
        all_rows.append({
            "TIMESTAMP": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"),
            "CODIGO_FABRICANTE": code,
            "SKU": None,
            "TITULO": None,
            "TOTAL_DISPONIBLES": None,
            "BODEGA": None,
            "BODEGA_PZAS": None,
            "PRECIO_21_MAS_CON_IVA": None,
            "PRECIO_21_MAS_SIN_IVA": None,
            "PRECIO_21_MAS_TEXTO": None,
            "URL_BUSQUEDA": build_search_url(code),
            "URL_PRODUCTO": None,
            "STATUS": f"ERROR: {repr(e)}"
        })

df_raw = pd.DataFrame(all_rows)

# Orden: primero SKU, luego precio (SIN IVA) de menor a mayor
df_raw["PRECIO_21_MAS_SIN_IVA"] = pd.to_numeric(df_raw["PRECIO_21_MAS_SIN_IVA"], errors="coerce")
df_raw["BODEGA_PZAS"] = pd.to_numeric(df_raw["BODEGA_PZAS"], errors="coerce")

df_raw_sorted = df_raw.sort_values(by=["SKU", "PRECIO_21_MAS_SIN_IVA"], ascending=[True, True]).reset_index(drop=True)
df_raw_sorted.head(20)

# ===== CELDA 8 =====
def weighted_quantile(values, weights, quantiles):
    values = np.asarray(values, dtype=float)
    weights = np.asarray(weights, dtype=float)
    quantiles = np.asarray(quantiles, dtype=float)

    sorter = np.argsort(values)
    values = values[sorter]
    weights = weights[sorter]

    cum_w = np.cumsum(weights)
    if cum_w[-1] == 0:
        return np.array([np.nan]*len(quantiles))
    cum_w = cum_w / cum_w[-1]
    return np.interp(quantiles, cum_w, values)

def percentiles_por_codigo_ponderados(df, percentiles=None):
    if percentiles is None:
        percentiles = [1,10,20,25,30,40,50,60,70,75,80,90,100]
    qs = [p/100 for p in percentiles]

    d = df.copy()
    d = d[(d["STATUS"]=="OK")]
    d["PRECIO_21_MAS_SIN_IVA"] = pd.to_numeric(d["PRECIO_21_MAS_SIN_IVA"], errors="coerce")
    d["BODEGA_PZAS"] = pd.to_numeric(d["BODEGA_PZAS"], errors="coerce")
    d = d.dropna(subset=["CODIGO_FABRICANTE","PRECIO_21_MAS_SIN_IVA","BODEGA_PZAS"])
    d = d[(d["PRECIO_21_MAS_SIN_IVA"]>0) & (d["BODEGA_PZAS"]>0)]

    rows=[]
    for code, g in d.groupby("CODIGO_FABRICANTE"):
        x = g["PRECIO_21_MAS_SIN_IVA"].values
        w = g["BODEGA_PZAS"].values
        qv = weighted_quantile(x, w, qs)
        row={"CODIGO_FABRICANTE": code, "TOTAL_PZAS": float(w.sum())}
        for p,val in zip(percentiles,qv):
            row[f"WP{p}"]=float(val)
        rows.append(row)
    return pd.DataFrame(rows)

def percentiles_por_sku_ponderados(df, percentiles=None):
    if percentiles is None:
        percentiles = [1,10,20,25,30,40,50,60,70,75,80,90,100]
    qs = [p/100 for p in percentiles]

    d = df.copy()
    d = d[(d["STATUS"]=="OK")]
    d["PRECIO_21_MAS_SIN_IVA"] = pd.to_numeric(d["PRECIO_21_MAS_SIN_IVA"], errors="coerce")
    d["BODEGA_PZAS"] = pd.to_numeric(d["BODEGA_PZAS"], errors="coerce")
    d = d.dropna(subset=["SKU","PRECIO_21_MAS_SIN_IVA","BODEGA_PZAS"])
    d = d[(d["PRECIO_21_MAS_SIN_IVA"]>0) & (d["BODEGA_PZAS"]>0)]

    rows=[]
    for sku, g in d.groupby("SKU"):
        x = g["PRECIO_21_MAS_SIN_IVA"].values
        w = g["BODEGA_PZAS"].values
        qv = weighted_quantile(x, w, qs)
        row={"SKU": sku, "TOTAL_PZAS": float(w.sum())}
        for p,val in zip(percentiles,qv):
            row[f"WP{p}"]=float(val)
        rows.append(row)
    return pd.DataFrame(rows)

def weighted_mean(x, w):
    x = np.asarray(x, dtype=float)
    w = np.asarray(w, dtype=float)
    s = w.sum()
    if s <= 0:
        return np.nan
    return float(np.sum(x*w)/s)

def robust_baseline_p25_p75(df_group):
    """
    Baseline robusto SOLO Abasteo:
    - calcula WP25 y WP75 ponderados por piezas
    - regresa promedio ponderado SOLO de piezas en [WP25, WP75]
    """
    x = df_group["PRECIO_21_MAS_SIN_IVA"].values.astype(float)
    w = df_group["BODEGA_PZAS"].values.astype(float)
    wp25, wp50, wp75 = weighted_quantile(x, w, [0.25, 0.50, 0.75])
    mask = (x >= wp25) & (x <= wp75)
    base = weighted_mean(x[mask], w[mask]) if mask.sum() else np.nan
    return float(wp25), float(wp50), float(wp75), base

def cheap_block_p1_p50(df_group):
    """
    Bloque barato SOLO Abasteo:
    - calcula WP1 y WP50 ponderados por piezas
    - regresa promedio ponderado SOLO de piezas en [WP1, WP50]
    """
    x = df_group["PRECIO_21_MAS_SIN_IVA"].values.astype(float)
    w = df_group["BODEGA_PZAS"].values.astype(float)
    wp1, wp50 = weighted_quantile(x, w, [0.01, 0.50])
    mask = (x >= wp1) & (x <= wp50)
    cheap = weighted_mean(x[mask], w[mask]) if mask.sum() else np.nan
    return float(wp1), float(wp50), cheap

def opportunity_from_abasteo(df_group):
    """
    Oportunidad SOLO por Abasteo (sin precio max del usuario):
    - baseline robusto = promedio ponderado en [WP25, WP75]
    - cheap block = promedio ponderado en [WP1, WP50]
    - gap% = (baseline - cheap)/baseline

    Además:
    - piezas_baratas = piezas con precio <= baseline*(1 - 0.05)  (5% debajo del baseline)
    - share_barato = piezas_baratas / total_piezas
    - clasificación: BAJA / MEDIA / ALTA

    Regresa dict con métricas y texto.
    """
    g = df_group.copy()
    g = g.dropna(subset=["PRECIO_21_MAS_SIN_IVA","BODEGA_PZAS"])
    g = g[(g["PRECIO_21_MAS_SIN_IVA"]>0) & (g["BODEGA_PZAS"]>0)]
    if g.empty:
        return {
            "OP_NIVEL":"SIN_DATA",
            "OP_GAP_%": np.nan,
            "OP_PZAS_BARATAS": 0,
            "OP_SHARE_BARATO_%": np.nan,
            "OP_BASELINE_P25_P75": np.nan,
            "OP_CHEAP_P1_P50": np.nan,
            "OP_UMBRAL_BARATO": np.nan,
            "OP_MENSAJE": "Sin datos suficientes para medir oportunidad."
        }

    wp25, wp50, wp75, baseline = robust_baseline_p25_p75(g)
    wp1, wp50b, cheap = cheap_block_p1_p50(g)

    total_pzas = float(g["BODEGA_PZAS"].sum())
    if not np.isfinite(baseline) or baseline <= 0 or not np.isfinite(cheap):
        return {
            "OP_NIVEL":"SIN_DATA",
            "OP_GAP_%": np.nan,
            "OP_PZAS_BARATAS": 0,
            "OP_SHARE_BARATO_%": np.nan,
            "OP_BASELINE_P25_P75": baseline,
            "OP_CHEAP_P1_P50": cheap,
            "OP_UMBRAL_BARATO": np.nan,
            "OP_MENSAJE": "No se pudo calcular baseline/cheap de forma estable."
        }

    gap = (baseline - cheap)/baseline * 100.0

    # Umbral para "piezas baratas": 5% debajo del baseline
    umbral = baseline * (1 - 0.05)
    piezas_baratas = float(g.loc[g["PRECIO_21_MAS_SIN_IVA"] <= umbral, "BODEGA_PZAS"].sum())
    share_barato = (piezas_baratas / total_pzas * 100.0) if total_pzas > 0 else np.nan

    # Clasificación (umbral doble: gap y cantidad)
    # Puedes ajustar estos criterios después sin tocar el resto
    if (gap >= 10 and piezas_baratas >= 500) or (gap >= 12 and share_barato >= 20):
        nivel = "ALTA"
    elif (gap >= 7 and piezas_baratas >= 200) or (gap >= 8 and share_barato >= 10):
        nivel = "MEDIA"
    elif (gap >= 4 and piezas_baratas >= 50):
        nivel = "BAJA"
    else:
        nivel = "NO"

    msg = (
        f"Oportunidad {nivel}: baseline robusto (P25–P75)=${baseline:,.2f} "
        f"vs bloque barato (P1–P50)=${cheap:,.2f} | gap={gap:.2f}%. "
        f"Piezas <= ${umbral:,.2f} (5% bajo baseline): {int(piezas_baratas):,} pzas "
        f"({share_barato:.2f}% del stock)."
    )

    return {
        "OP_NIVEL": nivel,
        "OP_GAP_%": float(gap),
        "OP_PZAS_BARATAS": int(round(piezas_baratas)),
        "OP_SHARE_BARATO_%": float(share_barato) if np.isfinite(share_barato) else np.nan,
        "OP_BASELINE_P25_P75": float(baseline),
        "OP_CHEAP_P1_P50": float(cheap),
        "OP_WP25": float(wp25),
        "OP_WP50": float(wp50),
        "OP_WP75": float(wp75),
        "OP_WP1": float(wp1),
        "OP_UMBRAL_BARATO": float(umbral),
        "OP_MENSAJE": msg
    }

# Percentiles (se siguen exportando como antes, ahora incluyen WP1 también)
df_pct = percentiles_por_codigo_ponderados(df_raw_sorted).sort_values(by=["CODIGO_FABRICANTE"]).reset_index(drop=True)
df_pct_sku = percentiles_por_sku_ponderados(df_raw_sorted).sort_values(by=["SKU"]).reset_index(drop=True)

df_pct.head()

# ===== CELDA 9 =====
def solver_max_qty_under_avg(prices, stocks, pmax):
    """
    Maximiza Q = sum(q_i) sujeto a sum(q_i * price_i)/sum(q_i) <= pmax
    Equivalente: sum(q_i*(price_i-pmax)) <= 0
    0 <= q_i <= stock_i
    - prices y stocks deben estar alineados
    - devuelve qty por item (entero), qty_total, avg_price
    """
    prices = np.asarray(prices, dtype=float)
    stocks = np.asarray(stocks, dtype=float)

    # a_i = price - pmax
    a = prices - pmax

    # tomar todo lo que está <= pmax
    q = np.zeros_like(stocks, dtype=float)

    neg = a <= 0
    q[neg] = stocks[neg]

    slack = float(-np.sum(q[neg] * a[neg]))  # slack disponible para "caros"
    # ahora elegir items caros con menor a_i (más cerca del pmax) para maximizar cantidad
    pos_idx = np.where(a > 0)[0]
    # ordenar por a ascendente
    pos_idx = pos_idx[np.argsort(a[pos_idx])]

    for i in pos_idx:
        if slack <= 0:
            break
        # cuánto puedo comprar aquí sin romper slack
        max_q = min(stocks[i], math.floor(slack / a[i]))
        if max_q <= 0:
            continue
        q[i] = max_q
        slack -= q[i] * a[i]

    qty_total = float(np.sum(q))
    if qty_total <= 0:
        return q, 0.0, np.nan

    avg_price = float(np.sum(q * prices) / qty_total)
    return q, qty_total, avg_price

def solver_with_target(prices, stocks, pmax, target_qty):
    """
    Si target_qty existe: intenta comprar lo máximo hasta target_qty (y si puede, llega),
    respetando promedio <= pmax. Si no puede llegar a target, devuelve máximo factible.
    """
    q, qty_total, avgp = solver_max_qty_under_avg(prices, stocks, pmax)

    if target_qty is None or (not np.isfinite(target_qty)):
        return q, qty_total, avgp

    target_qty = float(target_qty)
    if qty_total <= target_qty:
        return q, qty_total, avgp

    # Si el máximo excede el target, recortamos respetando el orden barato->caro:
    order = np.argsort(prices)
    q2 = np.zeros_like(q)
    remain = target_qty

    for i in order:
        if remain <= 0:
            break
        take = min(q[i], remain)
        # asegurar entero
        take = math.floor(take)
        if take <= 0:
            continue
        q2[i] = take
        remain -= take

    qty2 = float(np.sum(q2))
    avg2 = float(np.sum(q2*prices)/qty2) if qty2>0 else np.nan
    return q2, qty2, avg2

# ===== CELDA 10 =====
reco_rows = []
curva_rows = []
opp_rows = []

d_ok = df_raw_sorted[df_raw_sorted["STATUS"]=="OK"].copy()
d_ok = d_ok.dropna(subset=["SKU","PRECIO_21_MAS_SIN_IVA","BODEGA_PZAS"])

input_map = df_input.set_index("CODIGO_FABRICANTE").to_dict(orient="index")

for code, cfg in input_map.items():
    # --- COMPRA (SIEMPRE con tu precio máximo SIN IVA) ---
    pmax = float(cfg["PRECIO_MAX_SIN_IVA"])
    target = None
    if "CANTIDAD_OBJETIVO" in cfg and pd.notna(cfg["CANTIDAD_OBJETIVO"]):
        target = float(cfg["CANTIDAD_OBJETIVO"])

    g = d_ok[(d_ok["CODIGO_FABRICANTE"]==code) | (d_ok["SKU"]==code)].copy()

    if g.empty:
        reco_rows.append({
            "CODIGO_FABRICANTE": code,
            "SKU": None,
            "PRECIO_MAX_SIN_IVA": pmax,
            "CANTIDAD_OBJETIVO": target,
            "QTY_RECOMENDADA": 0,
            "AVG_COMPRA_SIN_IVA": np.nan,
            "STATUS": "NO_DATA"
        })
        opp_rows.append({
            "CODIGO_FABRICANTE": code,
            "SKU": None,
            "OP_NIVEL": "SIN_DATA",
            "OP_MENSAJE": "Sin datos suficientes para medir oportunidad."
        })
        continue

    sku = g["SKU"].dropna().iloc[0] if not g["SKU"].dropna().empty else code
    g = g.sort_values(by="PRECIO_21_MAS_SIN_IVA", ascending=True).reset_index(drop=True)

    prices = g["PRECIO_21_MAS_SIN_IVA"].values.astype(float)
    stocks = g["BODEGA_PZAS"].values.astype(float)

    q_take, qty_total, avg_price = solver_with_target(prices, stocks, pmax, target)

    # Curva compra (solo con lo que el solver compra)
    cum_qty = 0.0
    cum_cost = 0.0
    for i in range(len(g)):
        take = float(q_take[i])
        if take <= 0:
            continue
        cum_qty += take
        cum_cost += take * prices[i]
        curva_rows.append({
            "CODIGO_FABRICANTE": code,
            "SKU": sku,
            "BODEGA": g.loc[i,"BODEGA"],
            "PRECIO_SIN_IVA": prices[i],
            "STOCK_BODEGA": stocks[i],
            "COMPRA_EN_BODEGA": take,
            "ACUM_PZAS": cum_qty,
            "ACUM_PROMEDIO_SIN_IVA": (cum_cost/cum_qty) if cum_qty>0 else np.nan,
        })

    reco_rows.append({
        "CODIGO_FABRICANTE": code,
        "SKU": sku,
        "PRECIO_MAX_SIN_IVA": pmax,
        "CANTIDAD_OBJETIVO": target,
        "QTY_RECOMENDADA": int(qty_total),
        "AVG_COMPRA_SIN_IVA": avg_price,
        "STATUS": "OK" if qty_total>0 else "NO_FEASIBLE"
    })

    # --- OPORTUNIDAD (SOLO ABASTEO, NO usa tu pmax) ---
    op = opportunity_from_abasteo(g)
    op_row = {
        "CODIGO_FABRICANTE": code,
        "SKU": sku,
        **op
    }
    opp_rows.append(op_row)

df_reco = pd.DataFrame(reco_rows).sort_values(by=["SKU"]).reset_index(drop=True)
df_curva = pd.DataFrame(curva_rows).sort_values(by=["SKU","PRECIO_SIN_IVA"]).reset_index(drop=True)
df_oportunidad = pd.DataFrame(opp_rows).sort_values(by=["SKU"]).reset_index(drop=True)

# Export
out_file = f"abasteo_final_solver_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
with pd.ExcelWriter(out_file, engine="openpyxl") as writer:
    df_input.to_excel(writer, sheet_name="input", index=False)
    df_raw_sorted.to_excel(writer, sheet_name="raw_bodegas", index=False)
    df_reco.to_excel(writer, sheet_name="recomendacion_compra", index=False)
    df_curva.to_excel(writer, sheet_name="curva_compra", index=False)
    df_pct.to_excel(writer, sheet_name="percentiles_codigo", index=False)
    df_pct_sku.to_excel(writer, sheet_name="percentiles_sku", index=False)
    df_oportunidad.to_excel(writer, sheet_name="oportunidad_compra", index=False)

files.download(out_file)
out_file